# ChessboardPatternRecognition-CV
计算机视觉
一、项目功能简述
（一）功能概述
本次项目以国际象棋为主题，通过图像处理以及智能识别技术，我们组预期实现通过图片识别棋局情况，包括棋盘的定位以及各个棋子的位置与概况，程序首先将对图像中的棋盘和棋子进行自动识别与解析，从输入图像中检测棋盘区域并且划分为8*8的棋格，然后再将检测到的棋子位置、类型映射到棋盘中，最终生成标准的局面状态数据，构建标准的棋局局面。我们还计划引入AI棋手与棋局分析，然后系统将基于Web平台实现与用户之间的交互，提供简洁直观的操作页面，用户可以上传图像，程序将自动识别图像得到棋局，给用户提供棋局的识别结果，得到棋局分析建议，以及走法建议，用户也可以选择与AI棋手进行对弈。
（二）功能模块分解
1.图像处理：支持用户上传图片，通过图片识别棋盘建立棋盘坐标系
2.棋子检测：通过不同棋子的特征识别棋子的种类，通过目标检测判断每个棋盘格有没有棋子，并且加入一定的异常处理比如光线干扰或者有少部分遮挡物的情况。
3.构建棋局：将识别结果构建成标准棋局，并且检查识别结果是否符合常规，如果检测到异常比如说存在两个白王，则需要提示异常点重新识别
4.Web平台与AI棋手：与用户进行交互，提供最优走法推荐、局势评分、威胁预警，并且支持与AI棋手对弈。
二、功能的技术路径
一、图像处理
1.图片上传：使用 Web 框架（如 Python 的 Flask 或 Django）搭建服务器端，通过 HTML 的<input type="file">标签实现用户上传图片功能。在服务器端接收并保存用户上传的图片。
2.棋盘识别与坐标系建立：
1.使用霍夫变换：对于棋盘图像，由于棋盘由规则的方格组成，霍夫变换可以检测图像中的直线，从而找到棋盘的边界。先对图像进行灰度化处理，然后进行边缘检测（如 Canny 边缘检测），再使用霍夫变换检测直线，通过直线的交点确定棋盘的四个角点。
2.透视变换：根据检测到的四个角点，使用透视变换将棋盘图像转换为鸟瞰图，使棋盘方格呈现为标准的矩形。
3.建立坐标系：将转换后的棋盘划分为 8*8 的棋格，以左上角为原点 (0,0)，右下角为 (7,7)，每个棋格为一个单位，建立棋盘坐标系。

二、棋子检测

1.棋子特征识别：
1.使用深度学习模型：如卷积神经网络（CNN），可以选择预训练的模型（如 ResNet、VGG 等），并在国际象棋棋子图像数据集上进行微调。数据集可以通过收集不同角度、光照条件下的棋子图像来构建。
2.特征提取：CNN 模型能够自动学习棋子的特征，如形状、颜色等。在模型训练过程中，优化损失函数（如交叉熵损失函数）以提高模型的准确率。
2.目标检测：
1.使用目标检测算法：如 YOLO（You Only Look Once）系列算法或 Faster R-CNN。这些算法可以在图像中检测出每个棋子的位置和类别。
2.异常处理：对于光线干扰或部分遮挡的情况，可以采用数据增强技术（如亮度调整、添加噪声、随机遮挡等）来扩充数据集，使模型具有更强的鲁棒性。同时，在检测过程中，可以通过设置置信度阈值来过滤掉不可靠的检测结果。

三、构建棋局

1.生成标准棋局：将检测到的棋子位置和类型映射到 8*8 的棋盘中，生成标准的局面状态数据。可以使用二维数组来表示棋局，每个元素记录对应棋格上的棋子类型（如 “白车”、“黑象” 等）或为空。
2.异常检查：遍历生成的棋局数据，检查是否存在不符合常规的情况，如存在两个白王或两个黑王等。如果检测到异常，记录异常点的位置，并提示用户重新识别。
四、Web 平台与 AI 棋手
1.Web 平台搭建：使用 Web 框架（如 Flask 或 Django）搭建用户交互界面，提供简洁直观的操作页面。页面上包括图片上传按钮、棋局识别结果展示区域、分析建议和走法建议展示区域等。
2.AI 棋手与棋局分析：
1.使用博弈树算法：如 Minimax 算法结合 Alpha-Beta 剪枝，来评估棋局的局势并寻找最优走法。在博弈树中，每个节点表示一个棋局状态，通过递归搜索树的节点来评估不同走法的价值。
2.局势评分：根据棋子的价值、位置、控制区域等因素设计评分函数，对当前棋局进行评分。评分越高表示该方局势越有利。
3.威胁预警：通过分析棋子之间的相互关系，检测出可能存在的威胁，如对方棋子的攻击范围等，并向用户发出预警。
3.与用户交互：当用户上传图像后，程序自动识别图像得到棋局，将识别结果、分析建议和走法建议展示在 Web 页面上。用户也可以选择与 AI 棋手进行对弈，AI 棋手根据当前棋局状态计算并执行最优走法，更新棋局状态并展示给用户。
三、分工
（一）计算机视觉与模型训练  
1.数据收集与处理：收集公开棋盘数据集（如 Chess Pieces Dataset），若不足则自行拍摄并标注（使用 LabelImg 等工具）；完成数据清洗（剔除模糊/错误样本）、增强（旋转、透视变换、亮度调整）
2.图像预处理：实现数据增强（旋转、透视变换、亮度调整）与预处理（OpenCV 透视矫正、棋盘分格定位）。 
3.模型开发：搭建模型，完成棋盘检测、棋子分类（如 ResNet）及位置定位；优化模型性能（超参数调优、迁移学习、多模型融合）。  
4.接口对接：将模型导出为 TensorFlow.js 格式，或封装为 Flask/Django API 供前端调用，提供预测接口（如 REST API），与后端协作完成推理服务部署。 

（二）前端开发与可视化
1.原型设计：使用 Figma 设计 Web 界面原型，包含上传图片按钮、棋盘可视化区域、AI 走法推荐面板、沙盘推演交互模块。  
2.前端实现：使用 React/Vue 搭建响应式前端页面，实现用户上传图片、实时棋盘可视化、AI 走法推荐面板；集成 Chessboard.js 或自定义 Canvas/SVG 绘制棋盘（8x8 网格、棋子贴图）；动态渲染棋子位置（根据 API 返回的棋盘状态实时更新）；实现推荐走法动画，如棋子移动高亮、路径演示

（三）后端开发
1.后端框架搭建：基于 Flask 设计 RESTful API，支持图片上传、模型推理、AI 走法推荐功能；接入 Stockfish 引擎（通过 python-chess 库），生成并返回推荐走法（如返回 Top 3 策略）；设计数据库（如 SQLite/PostgreSQL）存储用户棋局历史（可选功能）
2.系统整合：协调前后端数据格式，使用 Postman 调试接口，确保数据无缝传输。

（四）测试与交付
1.测试设计：编写单元测试、集成测试、性能测试（Locust 压测 API 并发能力）。    
2.技术报告：基于 LaTeX 撰写报告（Overleaf 协作），包含算法流程图（如模型训练 Pipeline）、实验对比（如 YOLOv5 vs YOLOv8 的 mAP 指标）、失败案例分析（如棋子遮挡问题）。    
3.演示视频：使用 OBS 录制功能演示（上传图片 → 识别 → 走法推荐 → 沙盘推演），剪辑后提交至 B 站。  
4.成果提交：整理 GitHub 仓库（代码 + 文档 + 视频链接），确保 README 清晰标注依赖安装、快速启动命令。


四、开发规划与风险预测
（一）开发规划
时间节点 	工作任务内容
4.13-4.16	- 明确每位组员的职责（如数据处理、模型训练、前端开发等）- 梳理项目目标与功能模块，细化阶段性目标（MVP）
- 撰写并提交Proposal文档，完成项目立项
4.16-4.20	- 查阅相关文献和开源项目，调研现有的棋子识别解决方案（如YOLO、Segment Anything等）
- 确定采用的核心技术方案和模型结构
- 使用GitHub搭建项目仓库，统一开发环境和依赖（如Python版本、库等）
- 完成README初稿及代码结构框架搭建
4.21-5.11	- 收集相关公开棋盘图像数据集
- 如公开数据不足，使用拍摄方式自行采集并手动标注
- 对数据进行清洗和增强（如旋转、透视变换、裁剪、亮度调整）
- 使用OpenCV实现图像预处理（透视矫正、图像分割）
- 初步训练CV模型，并完成棋盘格识别、棋子分类与定位测试
5.12-5.25	- 分析识别效果与问题，对模型进行调整与优化（超参数调整、多模型融合等）
- 引入数据增强策略提升模型泛化能力
- 设计网页原型图
- 使用Flask/Django + Vue/React实现前后端基本交互功能：上传图片、返回识别结果
5.26-6.8	- 整合CV识别模型与Web前后端系统，实现核心功能闭环
- 设计并优化前端UI界面，提升用户交互体验
- 增加扩展功能模块： 
  • 接入chess AI进行走法建议（如Stockfish） 
• 实现沙盘推演、对战演示等功能
- 进行使用测试与bug修复
- 开始撰写技术报告初稿和开发文档
6.9-6.23	- 梳理项目整体结构，补充接口文档与使用说明
- 整理代码，注释完善，确保可读性与可维护性
- 完成技术报告定稿
- 录制系统演示视频（功能展示+操作流程）
- 提交项目所有成果物至平台或老师指定地点
（二）风险预测
风险点	应对措施
棋子识别准确率低	- 扩充数据量，增强数据多样性
- 使用迁移学习
- 尝试多模型对比优化
开发进度滞后	- 提前设定buffer时间
- 任务可视化管理（如使用GitHub Projects）
- 调整人力优先做核心功能
协作沟通不畅	- 每周召开线上/线下例会
- 明确每人分工和交付内容
- GitHub持续同步和代码Review机制
前后端接口不统一	- 提前规划接口格式
- 使用Postman等工具进行接口调试与联调测试

五、突破与创新点
我们计划在实现棋盘与棋子图像识别的基础功能之外，同时打造出具备高实用性与智能交互能力的综合系统。围绕“图像识别-局面还原-AI互动-数据存储”的逻辑，我们规划了以下三个突破与创新项：
(一)网页端实时拍照识别
令系统支持通过网页直接调用本地摄像头进行实时拍照，识别现实棋盘局面。用户无需先拍照再上传图像或安装其他插件，只需授权浏览器访问摄像头，即可在页面中实时预览并拍摄棋盘图像，系统随后将自动完成棋局辨别，同时保存在网页中。该功能能够显著提升系统的可用性和便捷性，为日常记录、课堂教学、移动操作等使用场景提供高效支持。
(二)AI对弈与策略分析
实现棋局直接对接国际象棋 AI 引擎，用户可基于拍摄图像还原出的局面，与 AI 从当前状态继续对弈，系统也可以提供走法建议等辅助功能。除此之外，我们还计划实现两台 AI 互相对弈，自动演绎棋局演化过程，帮助用户理解复杂变招或残局布局；
(三)图像化棋局存档系统
构建一套支持图像与棋谱双重管理的存档系统，每一次识别操作都生成以下信息：1.原始图像；2.自动提取的标准棋谱；3.棋局生成时间戳与来源标识；4.用户自定义标签与注释；5.对弈历史。将这些信息结构化到JSON文件中，再保存到本地或后端数据库中，可以在网页中直接读取对局继续对弈。
